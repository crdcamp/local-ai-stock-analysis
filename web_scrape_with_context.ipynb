{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3bd6be",
   "metadata": {},
   "source": [
    "# Retrieve Article Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f174a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and analyzing webpage...\n",
      "Article data extracted and saved to article_data.json\n",
      "Extraction successful! Data saved to article_data.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove excessive whitespace, newlines, and special characters\n",
    "    if text:\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII for simplicity\n",
    "        return text\n",
    "    return ''\n",
    "\n",
    "def extract_article_data(url):\n",
    "    # Define headers to mimic a browser and reduce blocking\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"Fetching and analyzing webpage...\")\n",
    "        # Fetch the webpage with headers\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html_content = response.text\n",
    "\n",
    "        # Parse HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Initialize context dictionary for the local AI\n",
    "        article_data = {\n",
    "            \"url\": url,\n",
    "            \"title\": \"\",\n",
    "            \"main_content\": [],\n",
    "            \"headings\": [],\n",
    "            \"metadata\": {\n",
    "                \"description\": \"\",\n",
    "                \"keywords\": \"\",\n",
    "                \"author\": \"\",\n",
    "                \"date\": \"\"\n",
    "            },\n",
    "            \"links\": [],\n",
    "            \"images\": []\n",
    "        }\n",
    "\n",
    "        # Extract title\n",
    "        title_tag = soup.find('title') or soup.find('h1')\n",
    "        article_data[\"title\"] = clean_text(title_tag.get_text()) if title_tag else \"No title found\"\n",
    "\n",
    "        # Extract metadata (common meta tags for description, keywords, author, date)\n",
    "        meta_tags = soup.find_all('meta')\n",
    "        for meta in meta_tags:\n",
    "            name = meta.get('name', '').lower()\n",
    "            content = meta.get('content', '')\n",
    "            if name == 'description':\n",
    "                article_data[\"metadata\"][\"description\"] = clean_text(content)\n",
    "            elif name == 'keywords':\n",
    "                article_data[\"metadata\"][\"keywords\"] = clean_text(content)\n",
    "            elif name == 'author':\n",
    "                article_data[\"metadata\"][\"author\"] = clean_text(content)\n",
    "            elif name in ('date', 'publish_date', 'publication_date'):\n",
    "                article_data[\"metadata\"][\"date\"] = clean_text(content)\n",
    "\n",
    "        # Extract headings (h1, h2, h3) for structure and context\n",
    "        for tag in soup.find_all(['h1', 'h2', 'h3']):\n",
    "            level = tag.name  # e.g., 'h1', 'h2'\n",
    "            text = clean_text(tag.get_text())\n",
    "            if text:\n",
    "                article_data[\"headings\"].append({\"level\": level, \"text\": text})\n",
    "\n",
    "        # Extract main content: look for common article containers\n",
    "        content_selectors = [\n",
    "            'article',  # HTML5 article tag\n",
    "            'div[class*=\"article\"]', 'div[id*=\"article\"]',\n",
    "            'div[class*=\"content\"]', 'div[id*=\"content\"]',\n",
    "            'div[class*=\"post\"]', 'div[id*=\"post\"]',\n",
    "            'main'  # HTML5 main tag\n",
    "        ]\n",
    "        main_content = []\n",
    "        for selector in content_selectors:\n",
    "            elements = soup.select(selector)\n",
    "            for element in elements:\n",
    "                paragraphs = element.find_all(['p', 'div', 'span'])\n",
    "                for p in paragraphs:\n",
    "                    text = clean_text(p.get_text())\n",
    "                    if text and len(text) > 50:  # Filter short, irrelevant text\n",
    "                        main_content.append(text)\n",
    "            if main_content:  # Stop if we found content\n",
    "                break\n",
    "\n",
    "        # Fallback: if no content found, grab all paragraphs\n",
    "        if not main_content:\n",
    "            paragraphs = soup.find_all('p')\n",
    "            for p in paragraphs:\n",
    "                text = clean_text(p.get_text())\n",
    "                if text and len(text) > 50:\n",
    "                    main_content.append(text)\n",
    "\n",
    "        article_data[\"main_content\"] = main_content if main_content else [\"No main content found\"]\n",
    "\n",
    "        # Extract links for context\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            link_text = clean_text(a_tag.get_text())\n",
    "            link_url = urljoin(url, a_tag['href'])  # Resolve relative URLs\n",
    "            if link_text and link_url:\n",
    "                article_data[\"links\"].append({\"text\": link_text, \"url\": link_url})\n",
    "\n",
    "        # Extract images for context\n",
    "        for img_tag in soup.find_all('img'):\n",
    "            src = urljoin(url, img_tag.get('src', ''))  # Resolve relative URLs\n",
    "            alt = clean_text(img_tag.get('alt', ''))\n",
    "            if src:\n",
    "                article_data[\"images\"].append({\"src\": src, \"alt\": alt})\n",
    "\n",
    "        # Save the structured data as JSON for the local AI\n",
    "        with open(\"article_data.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(article_data, file, indent=4, ensure_ascii=False)\n",
    "        print(\"Article data extracted and saved to article_data.json\")\n",
    "        \n",
    "        return article_data\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the page: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://finance.yahoo.com/\"\n",
    "    result = extract_article_data(url)\n",
    "    if result:\n",
    "        print(\"Extraction successful! Data saved to article_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8e0fc",
   "metadata": {},
   "source": [
    "# Analyze Results Using Local LLM\n",
    "\n",
    "This time we'll try using the ```ollama``` python library rather than ```smolagents```\n",
    "\n",
    "Also, we'll only provide in content of the page for the model to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08851d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the JSON Data:\n",
      "<think>\n",
      "Alright, let me try to figure out how to approach this query. The user has provided a task where I need to summarize web page content from Yahoo Finance based on specific criteria. They included a JSON data snippet which seems to be the main content to analyze.\n",
      "\n",
      "First, I should identify the key elements they want in the summary: main themes or topics, notable stock changes with context, significant events or announcements, and general market sentiment or implications.\n",
      "\n",
      "Looking at the JSON data, there are multiple entries, some repeated. It appears each line is a separate news snippet, mentioning various topics like Elon Musk's comments on DOGE, Trump's tariff policies, Anthropic's revenue, Google facing potential changes, and more. There are also mentions of stock tickers with percentage changes.\n",
      "\n",
      "I'll start by categorizing the main themes. It seems like the primary topics are围绕Trump的关税政策、科技公司的监管变化、加密货币的影响，以及宏观经济指标如就业数据和市场表现。\n",
      "\n",
      "Next, for each theme, I need to extract specific information. For Trump's tariffs, there are mentions of doubling steel and aluminum taxes, affecting companies like US Steel (X) and others. This could impact the market positively or negatively depending on trade relations.\n",
      "\n",
      "Then, looking at Google (GOOGL), there's a potential breakup due to antitrust concerns, which would be significant for competition and innovation in tech. Anthropic hitting $3B revenue shows growth in AI startups, highlighting the current trend towards AI investment.\n",
      "\n",
      "Stock changes are scattered throughout. Tesla (TSLA) is down, possibly due to regulatory or market shifts, while DOGE has seen a massive spike post-Musk's comments, indicating a strong influence of social media on crypto markets.\n",
      "\n",
      "For significant events, Trump's tariff announcement at a rally about US Steel acquisition by Nippon Steel is notable. This ties into broader trade policies and their impact on U.S. industries. The DOJ's lawsuit against Google for monopolistic practices could set precedents in tech regulation.\n",
      "\n",
      "Regarding market sentiment, the S&P 500 and Nasdaq had strong May gains, suggesting a positive trend entering June. However, the overall tone is mixed with risks like trade tensions and regulatory changes affecting different sectors variably.\n",
      "\n",
      "In terms of implications, investors might be cautious about relying on Trump's policies due to their unpredictability. The tech sector faces significant headwinds from antitrust actions, which could alter market dynamics. On the flip side, areas like AI and cybersecurity are booming, offering investment opportunities.\n",
      "\n",
      "I should structure the summary by first listing the main themes, then detailing notable stock changes with context, followed by key events, and finally discussing market sentiment and implications. This approach ensures clarity and addresses all user requirements systematically.\n",
      "</think>\n",
      "\n",
      "### Yahoo Finance Summary: May 29-June 1, 2023\n",
      "\n",
      "#### **Main Themes and Topics:**\n",
      "1. **Trade Policy and Tariffs**:\n",
      "   - President Trump announced plans to double tariffs on foreign steel and aluminum, particularly in response to Nippon Steel's acquisition of US Steel (X). This move is expected to have significant implications for trade relations and market dynamics.\n",
      "   - The announcement came during a rally where Trump emphasized stricter limits on China's tech sector.\n",
      "\n",
      "2. **Technology and Antitrust**:\n",
      "   - Google (GOOGL) faced potential regulatory scrutiny as the DOJ filed a lawsuit alleging anticompetitive practices in its dominance of digital advertising. This could have far-reaching implications for the tech industry.\n",
      "   - Discussions around \"Big Tech\" monopolies continued to dominate, with concerns about innovation and market competition.\n",
      "\n",
      "3. **Market Performance**:\n",
      "   - The S&P 500 and Nasdaq showed strong gains entering June, driven by optimism in AI and technology sectors.\n",
      "   - Crypto markets remained volatile, with DOGE (CCC) experiencing a massive spike after Elon Musk's comments on Twitter.\n",
      "\n",
      "4. **Earnings and Economic Data**:\n",
      "   - Lululemon (LULU) reported strong earnings, contributing to positive sentiment in the retail sector.\n",
      "   - JOLTS data and May jobs reports were highlighted as key economic indicators for market watchers.\n",
      "\n",
      "5. **Investment Trends**:\n",
      "   - Interest in AI startups like Anthropic grew, with the company hitting $3 billion in revenue, signaling a shift toward more responsible AI development.\n",
      "   - Private markets were also gaining traction as alternative investment avenues for retail investors.\n",
      "\n",
      "---\n",
      "\n",
      "### **Notable Stock Changes and Context:**\n",
      "- **Tesla (TSLA)**:\n",
      "  - Tesla shares dropped (-2.15%) amid concerns about regulatory changes in China's tech sector and potential supply chain disruptions.\n",
      "  \n",
      "- **DOGE (CCC)**:\n",
      "  - DOGE surged (+347%) following Elon Musk's tweet hinting at potential Dogecoin usage for his new Twitter account, showcasing the power of social media on crypto markets.\n",
      "\n",
      "- **US Steel (X)**:\n",
      "  - US Steel saw mixed reactions (+0.75% in some reports) as Nippon Steel's acquisition raised questions about trade policies and market consolidation.\n",
      "\n",
      "---\n",
      "\n",
      "### **Significant Events and Announcements:**\n",
      "1. **Trump's Tariff Announcement**:\n",
      "   - At a rally discussing Nippon Steel's acquisition of US Steel, Trump announced plans to double tariffs on foreign steel and aluminum. This move was seen as both a protectionist strategy and a potential escalation in trade tensions.\n",
      "\n",
      "2. **Google Antitrust Lawsuit**:\n",
      "   - The Department of Justice filed a major lawsuit against Google for monopolistic practices in digital advertising, marking a significant step in ongoing antitrust efforts targeting Big Tech.\n",
      "\n",
      "3. **AI and Crypto Trends**:\n",
      "   - Anthropic's $3 billion revenue milestone highlighted the growing importance of AI startups and ethical considerations in tech.\n",
      "   - DOGE's volatility underscored the risks and rewards of investing in cryptocurrency markets influenced by social media sentiment.\n",
      "\n",
      "---\n",
      "\n",
      "### **Market Sentiment and Implications:**\n",
      "- **Optimism in Tech**:\n",
      "  - The strong May performance of the S&P 500 and Nasdaq suggested investor confidence in AI-driven growth, despite ongoing regulatory uncertainties.\n",
      "  \n",
      "- **Risks and Uncertainties**:\n",
      "  - Trade tensions, regulatory crackdowns, and geopolitical instability remained key risks for investors. Particularly, the impact of Trump's tariff policies on global trade relations was closely watched.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Takeaways:**\n",
      "1. The tech sector faces significant headwinds from antitrust actions but also shows resilience through AI innovation.\n",
      "2. Cryptocurrency markets remain unpredictable, with social media sentiment playing a major role in price movements.\n",
      "3. Trade policy developments under Trump continue to shape market dynamics and investor sentiment.\n",
      "\n",
      "For more detailed analysis and live updates, investors are encouraged to follow Yahoo Finance's coverage of these topics.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import json\n",
    "\n",
    "def analyze_json():\n",
    "    # Load the JSON file\n",
    "    with open('article_data.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Prepare a focused prompt for the model\n",
    "    prompt = \"\"\"\n",
    "    You are a financial analyst tasked with summarizing web page content from Yahoo Finance. Your summary should include:\n",
    "    - Main themes or topics in the news (e.g., tariffs, stock market, AI, etc.).\n",
    "    - Notable stock ticker changes (e.g., gains, losses) and their context.\n",
    "    - Significant events or announcements (e.g., policy changes, corporate news).\n",
    "    - General sentiment or potential market implications.\n",
    "    \n",
    "\n",
    "    Here is the relevant JSON data:\n",
    "    Main Content: {main_content}\n",
    "    \"\"\".format(\n",
    "        main_content=json.dumps(data['main_content'], indent=2)\n",
    "    )\n",
    "\n",
    "    # Send the prompt to the Ollama model\n",
    "    response: ChatResponse = chat(\n",
    "        model='deepseek-r1:14b',  # Replace with your preferred model if needed\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Print the model's summary\n",
    "    print(\"Summary of the JSON Data:\")\n",
    "    print(response['message']['content'])\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5b811",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "This is definitely a better approach. A solid start to extending the implementation in a more useful context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
